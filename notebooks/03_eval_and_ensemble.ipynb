{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c66ac03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ§  Device: mps\n",
      "âœ… Test set: 5 samples\n"
     ]
    }
   ],
   "source": [
    "# =============================================================\n",
    "# ðŸ§© Ensemble Setup & Dataloader\n",
    "# =============================================================\n",
    "from pathlib import Path\n",
    "import torch, pandas as pd, numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "from PIL import Image\n",
    "\n",
    "# --- Directories ---\n",
    "PROJECT_ROOT = Path.cwd().parent if Path.cwd().name == \"notebooks\" else Path.cwd()\n",
    "DATA_DIR = PROJECT_ROOT / \"input_local\"\n",
    "CKPT_DIR = PROJECT_ROOT / \"output\" / \"checkpoints\"\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available()\n",
    "                      else (\"mps\" if getattr(torch.backends, \"mps\", None) and torch.backends.mps.is_available()\n",
    "                            else \"cpu\"))\n",
    "print(f\"ðŸ§  Device: {device}\")\n",
    "\n",
    "# --- Transforms ---\n",
    "try:\n",
    "    import albumentations as A\n",
    "    from albumentations.pytorch import ToTensorV2\n",
    "    valid_tfms = A.Compose([\n",
    "        A.Resize(518, 518),\n",
    "        A.Normalize(mean=(0.5,0.5,0.5), std=(0.5,0.5,0.5)),\n",
    "        ToTensorV2(),\n",
    "    ])\n",
    "except ImportError:\n",
    "    from torchvision import transforms\n",
    "    valid_tfms = transforms.Compose([\n",
    "        transforms.Resize((518,518)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.5]*3, std=[0.5]*3),\n",
    "    ])\n",
    "\n",
    "# --- Dataset ---\n",
    "class ImageOnlyDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, csv_path, img_root, transform):\n",
    "        self.df = pd.read_csv(csv_path)\n",
    "        self.img_root = Path(img_root)\n",
    "        self.transform = transform\n",
    "    def __len__(self): return len(self.df)\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        img = Image.open(self.img_root / row[\"image_path\"]).convert(\"RGB\")\n",
    "        import numpy as np\n",
    "        if \"albumentations\" in str(type(self.transform)):\n",
    "            img = np.array(img)\n",
    "            img = self.transform(image=img)[\"image\"]\n",
    "        else:\n",
    "            img = self.transform(img)\n",
    "        return img, row.get(\"sample_id\", f\"test_{idx}\")\n",
    "\n",
    "test_ds = ImageOnlyDataset(DATA_DIR / \"test.csv\", DATA_DIR, valid_tfms)\n",
    "test_dl = DataLoader(test_ds, batch_size=8, shuffle=False)\n",
    "print(f\"âœ… Test set: {len(test_ds)} samples\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f33699a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”¹ vit_base_patch14_dinov2.lvd142m\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for ImageRegressor:\n\tMissing key(s) in state_dict: \"head.2.weight\", \"head.2.bias\". \n\tUnexpected key(s) in state_dict: \"head.3.weight\", \"head.3.bias\". ",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 48\u001b[39m\n\u001b[32m     46\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mðŸ”¹ \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     47\u001b[39m m = ImageRegressor(name).to(device)\n\u001b[32m---> \u001b[39m\u001b[32m48\u001b[39m \u001b[43mm\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     49\u001b[39m m.eval()\n\u001b[32m     50\u001b[39m preds = []\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/torch/nn/modules/module.py:2629\u001b[39m, in \u001b[36mModule.load_state_dict\u001b[39m\u001b[34m(self, state_dict, strict, assign)\u001b[39m\n\u001b[32m   2621\u001b[39m         error_msgs.insert(\n\u001b[32m   2622\u001b[39m             \u001b[32m0\u001b[39m,\n\u001b[32m   2623\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mMissing key(s) in state_dict: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m. \u001b[39m\u001b[33m\"\u001b[39m.format(\n\u001b[32m   2624\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33m, \u001b[39m\u001b[33m\"\u001b[39m.join(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m missing_keys)\n\u001b[32m   2625\u001b[39m             ),\n\u001b[32m   2626\u001b[39m         )\n\u001b[32m   2628\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(error_msgs) > \u001b[32m0\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m2629\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m   2630\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mError(s) in loading state_dict for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m\"\u001b[39m.format(\n\u001b[32m   2631\u001b[39m             \u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m, \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[33m\"\u001b[39m.join(error_msgs)\n\u001b[32m   2632\u001b[39m         )\n\u001b[32m   2633\u001b[39m     )\n\u001b[32m   2634\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[31mRuntimeError\u001b[39m: Error(s) in loading state_dict for ImageRegressor:\n\tMissing key(s) in state_dict: \"head.2.weight\", \"head.2.bias\". \n\tUnexpected key(s) in state_dict: \"head.3.weight\", \"head.3.bias\". "
     ]
    }
   ],
   "source": [
    "# =============================================================\n",
    "# ðŸ§  Load Multiple Models & Generate Safe Predictions\n",
    "# =============================================================\n",
    "import torch.nn as nn\n",
    "from timm import create_model\n",
    "\n",
    "class ImageRegressor(nn.Module):\n",
    "    def __init__(self, name, num_outputs=5):\n",
    "        super().__init__()\n",
    "        self.backbone = create_model(name, pretrained=False, num_classes=0)\n",
    "        in_features = getattr(self.backbone, \"embed_dim\", None) or getattr(self.backbone, \"num_features\", 1024)\n",
    "        hidden = 768 if \"vit\" in name else 512\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Linear(in_features, hidden), nn.ReLU(), nn.Linear(hidden, num_outputs)\n",
    "        )\n",
    "    def forward(self, x): return self.head(self.backbone(x))\n",
    "\n",
    "def safe_inverse_log(x):\n",
    "    if np.percentile(np.abs(x), 90) < 15 and x.max() < 30:\n",
    "        y = np.expm1(x)\n",
    "        if np.percentile(y, 99) < 1e6:\n",
    "            return np.clip(y, 0, None)\n",
    "    return np.clip(x, 0, None)\n",
    "\n",
    "def infer_with_tta(model, imgs):\n",
    "    v = [imgs,\n",
    "         torch.flip(imgs,[2]), torch.flip(imgs,[3]),\n",
    "         torch.rot90(imgs,1,[2,3]), torch.rot90(imgs,2,[2,3]), torch.rot90(imgs,3,[2,3])]\n",
    "    preds = [model(x) for x in v]\n",
    "    return torch.stack(preds).mean(0)\n",
    "\n",
    "# --- Models to ensemble ---\n",
    "MODELS = [\n",
    "    (\"vit_base_patch14_dinov2.lvd142m\", CKPT_DIR / \"vit_base_patch14_dinov2.lvd142m_best.pth\"),\n",
    "    (\"efficientnet_b0\", CKPT_DIR / \"efficientnet_b0_best.pth\"),\n",
    "    (\"efficientnet_b3\", CKPT_DIR / \"efficientnet_b3_best.pth\"),\n",
    "    (\"effnet_b0_fusion\", CKPT_DIR / \"effnet_b0_fusion_best.pth\"),\n",
    "]\n",
    "\n",
    "target_cols = [\"Dry_Clover_g\",\"Dry_Dead_g\",\"Dry_Green_g\",\"Dry_Total_g\",\"GDM_g\"]\n",
    "all_preds = []\n",
    "\n",
    "for name, path in MODELS:\n",
    "    if not path.exists(): \n",
    "        print(f\"âš ï¸ Missing: {path.name}\"); continue\n",
    "    print(f\"ðŸ”¹ {name}\")\n",
    "    m = ImageRegressor(name).to(device)\n",
    "    m.load_state_dict(torch.load(path, map_location=device))\n",
    "    m.eval()\n",
    "    preds = []\n",
    "    with torch.no_grad():\n",
    "        for imgs, _ in test_dl:\n",
    "            imgs = imgs.to(device)\n",
    "            out = infer_with_tta(m, imgs).cpu().numpy()\n",
    "            preds.append(safe_inverse_log(out))\n",
    "    all_preds.append(np.concatenate(preds))\n",
    "\n",
    "ensemble_preds = np.mean(all_preds, axis=0)\n",
    "print(f\"âœ… Ensemble preds shape: {ensemble_preds.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a9671a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================\n",
    "# ðŸ“ˆ Cell 3 â€” Save Ensemble Submission + Optional Local Evaluation\n",
    "# =============================================================\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "# -----------------------------\n",
    "# ðŸ”¹ Prepare for submission\n",
    "# -----------------------------\n",
    "sub_df = preds_df.melt(id_vars=\"image_path\", var_name=\"target_name\", value_name=\"target\")\n",
    "\n",
    "# Use same mapping logic as Kaggle requires\n",
    "if \"sample_id\" not in test_df.columns:\n",
    "    test_df[\"sample_id\"] = test_df[\"image_path\"] + \"__\" + test_df[\"target_name\"]\n",
    "\n",
    "final_sub = (\n",
    "    test_df[[\"sample_id\", \"image_path\", \"target_name\"]]\n",
    "    .merge(sub_df, on=[\"image_path\", \"target_name\"], how=\"left\")\n",
    "    .drop_duplicates(subset=[\"sample_id\"])\n",
    ")\n",
    "\n",
    "# -----------------------------\n",
    "# ðŸ”¹ Save to output directory\n",
    "# -----------------------------\n",
    "OUT_DIR = CKPT_DIR.parent / \"submissions\"\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "sub_path = OUT_DIR / \"ensemble_submission.csv\"\n",
    "\n",
    "final_sub[[\"sample_id\", \"target\"]].to_csv(sub_path, index=False)\n",
    "print(f\"ðŸ’¾ Saved ensemble submission â†’ {sub_path.resolve()}\")\n",
    "print(f\"ðŸ“¦ Submission shape: {final_sub.shape}\")\n",
    "\n",
    "# -----------------------------\n",
    "# ðŸ”¹ Optional: local ground-truth evaluation (if available)\n",
    "# -----------------------------\n",
    "gt_path = DATA_DIR / \"test_ground_truth.csv\"\n",
    "if gt_path.exists():\n",
    "    gt = pd.read_csv(gt_path)\n",
    "    merged = final_sub.merge(gt, on=\"sample_id\", suffixes=(\"_pred\", \"_true\"))\n",
    "    rmse = np.sqrt(np.mean((merged[\"target_pred\"] - merged[\"target_true\"])**2))\n",
    "    mae  = np.mean(np.abs(merged[\"target_pred\"] - merged[\"target_true\"]))\n",
    "    print(f\"ðŸ“Š Local RMSE: {rmse:.3f} | MAE: {mae:.3f}\")\n",
    "else:\n",
    "    print(\"â„¹ï¸ No local ground truth found â€” skipping evaluation.\")\n",
    "\n",
    "print(\"ðŸ Ensemble submission ready for Kaggle upload.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38f3bac8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
