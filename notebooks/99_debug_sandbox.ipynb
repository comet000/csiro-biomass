{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "95b6123d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Project root detected: /Users/olia_/projects/Kaggle/csiro-biomass\n",
      "üß© Running on: Local environment\n",
      "‚öôÔ∏è Device detected: mps | GPU available: True\n",
      "üì¶ Imports OK ‚Äî config, data_loading, and model_utils are accessible.\n",
      "DATA_DIR: /Users/olia_/projects/Kaggle/csiro-biomass/input_local\n",
      "TRAIN_IMG_DIR: True ‚Üí /Users/olia_/projects/Kaggle/csiro-biomass/input_local/train\n",
      "TEST_IMG_DIR:  True  ‚Üí /Users/olia_/projects/Kaggle/csiro-biomass/input_local/test\n",
      "\n",
      "‚úÖ Environment bootstrap complete ‚Äî safe to proceed.\n"
     ]
    }
   ],
   "source": [
    "# =============================================================\n",
    "# üß≠ UNIVERSAL ENVIRONMENT BOOTSTRAP ‚Äî Local / Kaggle CPU / Kaggle GPU\n",
    "# =============================================================\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import torch\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 1Ô∏è‚É£ Detect project root (auto-resolve for any run location)\n",
    "# -------------------------------------------------------------\n",
    "CWD = Path.cwd().resolve()\n",
    "\n",
    "if (CWD / \"src\").exists():\n",
    "    PROJECT_ROOT = CWD\n",
    "elif (CWD.name == \"notebooks\") and (CWD.parent / \"src\").exists():\n",
    "    PROJECT_ROOT = CWD.parent\n",
    "else:\n",
    "    PR = CWD\n",
    "    for _ in range(3):\n",
    "        if (PR / \"src\").exists():\n",
    "            PROJECT_ROOT = PR\n",
    "            break\n",
    "        PR = PR.parent\n",
    "    else:\n",
    "        raise RuntimeError(\"‚ùå Could not locate project root containing 'src/' folder.\")\n",
    "\n",
    "# Ensure src/ is importable\n",
    "if str(PROJECT_ROOT) not in sys.path:\n",
    "    sys.path.insert(0, str(PROJECT_ROOT))\n",
    "\n",
    "print(f\"‚úÖ Project root detected: {PROJECT_ROOT}\")\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 2Ô∏è‚É£ Environment flags\n",
    "# -------------------------------------------------------------\n",
    "IS_KAGGLE = Path(\"/kaggle\").exists()\n",
    "DEVICE = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if getattr(torch.backends, \"mps\", None)\n",
    "    and torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "IS_GPU = DEVICE in (\"cuda\", \"mps\")\n",
    "\n",
    "print(f\"üß© Running on: {'Kaggle' if IS_KAGGLE else 'Local'} environment\")\n",
    "print(f\"‚öôÔ∏è Device detected: {DEVICE} | GPU available: {IS_GPU}\")\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 3Ô∏è‚É£ Import core project modules\n",
    "# -------------------------------------------------------------\n",
    "from src import config\n",
    "from src.data_loading import load_train_data, load_test_data\n",
    "from src.model_utils import build_model\n",
    "\n",
    "print(\"üì¶ Imports OK ‚Äî config, data_loading, and model_utils are accessible.\")\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 4Ô∏è‚É£ Verify essential paths\n",
    "# -------------------------------------------------------------\n",
    "print(f\"DATA_DIR: {config.DATA_DIR}\")\n",
    "print(f\"TRAIN_IMG_DIR: {config.TRAIN_IMG_DIR.exists()} ‚Üí {config.TRAIN_IMG_DIR}\")\n",
    "print(f\"TEST_IMG_DIR:  {config.TEST_IMG_DIR.exists()}  ‚Üí {config.TEST_IMG_DIR}\")\n",
    "\n",
    "print(\"\\n‚úÖ Environment bootstrap complete ‚Äî safe to proceed.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "242ef2d7",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "25889816",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÇ DATA DIRECTORY OVERVIEW\n",
      "DATA_DIR:        /Users/olia_/projects/Kaggle/csiro-biomass/input_local\n",
      "TRAIN_IMG_DIR:   True ‚Üí /Users/olia_/projects/Kaggle/csiro-biomass/input_local/train\n",
      "TEST_IMG_DIR:    True  ‚Üí /Users/olia_/projects/Kaggle/csiro-biomass/input_local/test\n",
      "TRAIN_CSV:       True ‚Üí /Users/olia_/projects/Kaggle/csiro-biomass/input_local/train.csv\n",
      "TEST_CSV:        True  ‚Üí /Users/olia_/projects/Kaggle/csiro-biomass/input_local/test.csv\n",
      "\n",
      "üìä DATAFRAME SHAPES\n",
      "   train_df: (1785, 9) | image_col='image_path' | target_col='target'\n",
      "   test_df:  (5, 3)  | image_col='image_path'\n",
      "\n",
      "üß≠ TRAIN COLUMNS: ['sample_id', 'image_path', 'Sampling_Date', 'State', 'Species', 'Pre_GSHH_NDVI', 'Height_Ave_cm', 'target_name', 'target']\n",
      "üß≠ TEST  COLUMNS: ['sample_id', 'image_path', 'target_name']\n",
      "\n",
      "üîé Missing values (train):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "sample_id        0\n",
       "image_path       0\n",
       "Sampling_Date    0\n",
       "State            0\n",
       "Species          0\n",
       "Pre_GSHH_NDVI    0\n",
       "Height_Ave_cm    0\n",
       "target_name      0\n",
       "target           0\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîé Missing values (test):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "sample_id      0\n",
       "image_path     0\n",
       "target_name    0\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üñºÔ∏è Train image sample stats: {'n_examined': 100, 'missing': 0, 'bad': 0, 'sizes_count': 100, 'width_mean': 2000.0, 'height_mean': 1000.0, 'width_min': 2000, 'height_min': 1000, 'width_max': 2000, 'height_max': 1000}\n",
      "üñºÔ∏è Test  image sample stats: {'n_examined': 5, 'missing': 0, 'bad': 0, 'sizes_count': 5, 'width_mean': 2000.0, 'height_mean': 1000.0, 'width_min': 2000, 'height_min': 1000, 'width_max': 2000, 'height_max': 1000}\n",
      "\n",
      "‚úÖ Data layout verified successfully.\n"
     ]
    }
   ],
   "source": [
    "# =============================================================\n",
    "# üß© DATA LAYOUT VERIFICATION ‚Äî Safe for Local + Kaggle\n",
    "# =============================================================\n",
    "from pathlib import Path\n",
    "from src import config\n",
    "from src.data_loading import load_train_data, load_test_data, sample_image_stats\n",
    "\n",
    "print(\"üìÇ DATA DIRECTORY OVERVIEW\")\n",
    "print(f\"DATA_DIR:        {config.DATA_DIR}\")\n",
    "print(f\"TRAIN_IMG_DIR:   {config.TRAIN_IMG_DIR.exists()} ‚Üí {config.TRAIN_IMG_DIR}\")\n",
    "print(f\"TEST_IMG_DIR:    {config.TEST_IMG_DIR.exists()}  ‚Üí {config.TEST_IMG_DIR}\")\n",
    "print(f\"TRAIN_CSV:       {config.TRAIN_CSV.exists()} ‚Üí {config.TRAIN_CSV}\")\n",
    "print(f\"TEST_CSV:        {config.TEST_CSV.exists()}  ‚Üí {config.TEST_CSV}\")\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 1Ô∏è‚É£ Load CSVs safely\n",
    "# -------------------------------------------------------------\n",
    "train_df, train_img_col, target_col = load_train_data()\n",
    "test_df,  test_img_col = load_test_data()\n",
    "\n",
    "print(\"\\nüìä DATAFRAME SHAPES\")\n",
    "print(f\"   train_df: {train_df.shape} | image_col='{train_img_col}' | target_col='{target_col}'\")\n",
    "print(f\"   test_df:  {test_df.shape}  | image_col='{test_img_col}'\")\n",
    "\n",
    "print(\"\\nüß≠ TRAIN COLUMNS:\", list(train_df.columns))\n",
    "print(\"üß≠ TEST  COLUMNS:\", list(test_df.columns))\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 2Ô∏è‚É£ Missing values check\n",
    "# -------------------------------------------------------------\n",
    "print(\"\\nüîé Missing values (train):\")\n",
    "display(train_df.isna().sum())\n",
    "print(\"\\nüîé Missing values (test):\")\n",
    "display(test_df.isna().sum())\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 3Ô∏è‚É£ Optional: Sample image stats (quick integrity probe)\n",
    "# -------------------------------------------------------------\n",
    "train_stats = sample_image_stats(train_df, image_path_col=\"image_path\", max_samples=100)\n",
    "test_stats  = sample_image_stats(test_df,  image_path_col=\"image_path\", max_samples=50)\n",
    "\n",
    "print(\"\\nüñºÔ∏è Train image sample stats:\", train_stats)\n",
    "print(\"üñºÔ∏è Test  image sample stats:\",  test_stats)\n",
    "\n",
    "print(\"\\n‚úÖ Data layout verified successfully.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
